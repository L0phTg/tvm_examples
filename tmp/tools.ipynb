{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for deferring annotation parsing in TVMScript\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm import relay\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import ir as I\n",
    "from tvm.script import tir as T\n",
    "from tvm.script import relax as R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te\n",
    "from tvm import topi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import relax as rx, tir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import fx\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写tir函数时，注意：\n",
    "- bb.emit\n",
    "- bb.emit_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn_params = {\n",
    "    \"w0\": None, \"b0\": None,\n",
    "    \"w1\": None, \"b1\": None\n",
    "}\n",
    "addnorm_params = {\n",
    "    \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性层Linear\n",
    "- dense+add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_linear(X: te.Tensor, W: te.Tensor, B: te.Tensor, Z: te.Tensor) -> te.Tensor:\n",
    "    Y = topi.nn.matmul(X, W, bias=B)\n",
    "    res = topi.add(Y, Z)\n",
    "    return res\n",
    "\n",
    "def te_linear_func():\n",
    "    b = te.var(\"batch\") # batch\n",
    "    indim = te.var(\"indim\") # indim\n",
    "    outdim = te.var(\"outdim\") # outdim\n",
    "    X = te.placeholder(shape=(b, indim), name=\"x\", dtype=\"float32\")\n",
    "    W = te.placeholder(shape=(outdim, indim), name=\"w\", dtype=\"float32\")\n",
    "    B = te.placeholder(shape=(outdim, ), name=\"b\", dtype=\"float32\")\n",
    "    Z = te.placeholder(shape=(b, outdim), name=\"z\", dtype=\"float32\")\n",
    "    Y = topi.nn.matmul(X, W, bias=B)\n",
    "    res = topi.add(Y, Z)\n",
    "    return te.create_prim_func([X, W, B, Z, res]).with_attr(\"global_symbol\", \"linear\")\n",
    "\n",
    "def linear(X: R.Tensor) -> R.Tensor:\n",
    "    res = te_linear_func()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "relu, 动态shape："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_func():\n",
    "    m = te.var(\"m\")\n",
    "    n = te.var(\"n\")\n",
    "    X = te.placeholder(shape=(m, n), name=\"x\", dtype=\"float32\")\n",
    "    Y = topi.nn.relu(X)\n",
    "    return te.create_prim_func([X, Y]).with_attr(\"global_symbol\", \"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFN, 前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PositiveWiseFFN():\n",
    "    bb = relax.BlockBuilder()\n",
    "    # bb.add_func(te_linear_func(), \"linear\")\n",
    "    # bb.add_func(relu_func(), \"relu\")\n",
    "    b = tir.Var(\"b\", \"int64\") \n",
    "    m, n, d = tir.Var(\"n\", \"int64\"), tir.Var(\"m\", \"int64\"), tir.Var(\"d\", \"int64\")\n",
    "    # 动态shape anno\n",
    "    type_anno = rx.DynTensorType(2, \"float32\")\n",
    "    type_anno1 = rx.DynTensorType(1, \"float32\")\n",
    "    x = rx.Var(\"x\", [b, m], type_anno)\n",
    "    w0 = rx.Var(\"w0\", [n, m], type_anno)\n",
    "    b0 = rx.Var(\"b0\", [n, ], type_anno1)\n",
    "    z0 = rx.Var(\"z0\", [b, n], type_anno)\n",
    "\n",
    "    w1 = rx.Var(\"w1\", [d, n], type_anno)\n",
    "    b1 = rx.Var(\"b1\", [d, ], type_anno1)\n",
    "    z1 = rx.Var(\"z1\", [b, d], type_anno)\n",
    "    fn_inputs = [x, w0, b0, z0, w1, b1, z1]\n",
    "    fn_output = None\n",
    "    with bb.function(\"positivewiseffn\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit_te(te_linear, x, w0, b0, z0)\n",
    "            lv1 = bb.emit_te(topi.nn.relu, lv0)\n",
    "            output = bb.emit_te(te_linear, lv1, w1, b1, z1)\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_linear</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_3: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_2, [m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_3, [b, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_add <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_add, [b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        T_matmul_NN <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        compute <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, n, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[k, j]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                i, j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN[i, j], rxplaceholder_2[j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[i, j])\n",
       "                compute[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_2[j]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(compute[ax0, ax1], rxplaceholder_3[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[ax0, ax1])\n",
       "                T_add[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> compute[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_3[ax0, ax1]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">relu</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, m: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64, n: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        compute <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_compute, [b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                i0_1, i1_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i0_1, i1_1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[i0_1, i1_1])\n",
       "                compute[i0_1, i1_1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(rxplaceholder[i0_1, i1_1], T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>))\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_linear1</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_3: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, n: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        d <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [d, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_2, [d], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_3, [b, d], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_add <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_add, [b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(m, d)], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        T_matmul_NN <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        compute <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, m, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_matmul_NN&quot;</span>):\n",
       "                i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[i, k], rxplaceholder_1[k, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_matmul_NN[i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[k, j]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, m):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "                i, j <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(T_matmul_NN[i, j], rxplaceholder_2[j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[i, j])\n",
       "                compute[i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_matmul_NN[i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_2[j]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(m, d)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(compute[ax0, ax1], rxplaceholder_3[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[ax0, ax1])\n",
       "                T_add[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> compute[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_3[ax0, ax1]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">positivewiseffn</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;m&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), z0: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), w1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;d&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), b1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;d&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), z1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;d&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">2</span>):\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        d <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_linear, (x, w0, b0, z0), (b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(relu, (lv,), (b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(n, m)), (m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_linear1, (lv1, w1, b1, z1), (b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(m, d)), (n,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(m, d)), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PositiveWiseFFN().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差连接和层规范化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_layernorm(X: te.Tensor, gamma: te.Tensor, beta: te.Tensor):\n",
    "    out = topi.nn.layer_norm(X, gamma, beta, axis=[-1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = te.placeholder(shape=(128, 128), name=\"A\", dtype=\"float32\")\n",
    "gamma = te.placeholder(shape=(128, ), name=\"Gamma\", dtype=\"float32\")\n",
    "beta = te.placeholder(shape=(128, ), name=\"Beta\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addnorm():\n",
    "    bb = relax.BlockBuilder()\n",
    "    b = tir.Var(\"b\", \"int64\")\n",
    "    m, n, k = tir.Var(\"m\", \"int64\"), tir.Var(\"n\", \"int64\"), tir.Var(\"k\", \"int64\")    \n",
    "    \n",
    "    type_anno = rx.DynTensorType(3, \"float32\")\n",
    "    type_anno1 = rx.DynTensorType(1, \"float32\")\n",
    "    \n",
    "    x = rx.Var(\"x\", [b, m, n], type_anno)\n",
    "    gamma = rx.Var(\"gamma\", [n], type_anno1)\n",
    "    beta = rx.Var(\"beta\", [n], type_anno1)\n",
    "    fn_inputs = [x, gamma, beta]\n",
    "    fn_output = None\n",
    "    with bb.function(\"addnorm\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(R.TupleGetItem(relax.nn.dropout(x), 1))\n",
    "            lv1 = bb.emit_te(topi.add, lv0, x)\n",
    "            output = bb.emit_te(te_layernorm, lv1, gamma, beta)\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">add</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_add: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b, m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [b, m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_add <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_add, [b, m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, m, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_add&quot;</span>):\n",
       "                ax0, ax1, ax2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[ax0, ax1, ax2], rxplaceholder_1[ax0, ax1, ax2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_add[ax0, ax1, ax2])\n",
       "                T_add[ax0, ax1, ax2] <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder[ax0, ax1, ax2] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_1[ax0, ax1, ax2]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">te_layernorm</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_layer_norm: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b, m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_2, [n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_layer_norm <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_layer_norm, [b, m, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        rxplaceholder_red_temp_v0 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_red_temp_v1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>alloc_buffer([b, m], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, m, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;rxplaceholder_red_temp&quot;</span>):\n",
       "                ax0, ax1, k2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[ax0, ax1, k2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(rxplaceholder_red_temp_v0[ax0, ax1], rxplaceholder_red_temp_v1[ax0, ax1])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                    rxplaceholder_red_temp_v1[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                v_rxplaceholder_red_temp_v0: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[ax0, ax1, k2]\n",
       "                v_rxplaceholder_red_temp_v1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> rxplaceholder_red_temp_v1[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[ax0, ax1, k2] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder[ax0, ax1, k2]\n",
       "                rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> v_rxplaceholder_red_temp_v0\n",
       "                rxplaceholder_red_temp_v1[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> v_rxplaceholder_red_temp_v1\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b, m, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_layer_norm&quot;</span>):\n",
       "                ax0, ax1, ax2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSS&quot;</span>, [i0, i1, i2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[ax0, ax1, ax2], rxplaceholder_red_temp_v0[ax0, ax1], rxplaceholder_red_temp_v1[ax0, ax1], rxplaceholder_1[ax2], rxplaceholder_2[ax2])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_layer_norm[ax0, ax1, ax2])\n",
       "                T_layer_norm[ax0, ax1, ax2] <span style=\"color: #AA22FF; font-weight: bold\">=</span> (rxplaceholder[ax0, ax1, ax2] <span style=\"color: #AA22FF; font-weight: bold\">-</span> rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">/</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, n)) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>rsqrt(rxplaceholder_red_temp_v1[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">/</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, n) <span style=\"color: #AA22FF; font-weight: bold\">-</span> rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">/</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, n) <span style=\"color: #AA22FF; font-weight: bold\">*</span> (rxplaceholder_red_temp_v0[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">/</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, n)) <span style=\"color: #AA22FF; font-weight: bold\">+</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">1.0000000000000001e-05</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[ax2] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder_2[ax2]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">addnorm</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), gamma: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;n&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), beta: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;n&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dropout(x, rate<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0.5</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv[<span style=\"color: #008000\">1</span>]\n",
       "            lv2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(add, (lv1, x), (b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(te_layernorm, (lv2, gamma, beta), (b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, m, n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv3\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "addnorm().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_qkv(num_heads=2):\n",
    "    bb = relax.BlockBuilder()\n",
    "    b = T.Var(\"b\", \"int64\")\n",
    "    m, n = T.Var(\"m\", \"int64\"), T.Var(\"n\", \"int64\")\n",
    "\n",
    "    type_anno = rx.DynTensorType(3, \"float32\")\n",
    "    x = rx.Var(\"x\", [b, m, n], type_anno)\n",
    "\n",
    "    fn_inputs = [x]\n",
    "    fn_output = None\n",
    "    with bb.function(\"transpose_qkv\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.reshape(x, (b, m, num_heads, -1)))\n",
    "            lv1 = bb.emit(relax.op.transpose(lv0, (0, 2, 1, 3)))\n",
    "            output = bb.emit(relax.op.reshape(lv1, (-1, lv1.shape[2], lv1.shape[3])))\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()\n",
    "\n",
    "def transpose_output(num_heads=2):\n",
    "    bb = relax.BlockBuilder()\n",
    "    bh = T.Var(\"bh\", \"int64\")\n",
    "    m, ndh = T.Var(\"m\", \"int64\"), T.Var(\"ndh\", \"int64\")\n",
    "    \n",
    "    type_anno = rx.DynTensorType(3, \"float32\")    \n",
    "    x = rx.Var(\"x\", [bh, m, ndh], type_anno)\n",
    "\n",
    "    fn_inputs = [x]\n",
    "    fn_output = None\n",
    "    with bb.function(\"transpose_output\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.reshape(x, (-1, num_heads, m, ndh)))\n",
    "            lv1 = bb.emit(relax.op.transpose(lv0, (0, 2, 1, 3)))\n",
    "            output = bb.emit(relax.op.reshape(lv1, (lv1.shape[0], lv1.shape[1], -1)))\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">transpose_qkv</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, m, <span style=\"color: #008000\">2</span>, (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (b, m, <span style=\"color: #008000\">2</span>, <span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>))\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((b, <span style=\"color: #008000\">2</span>, m, (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose(lv, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>])\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))) <span style=\"color: #AA22FF; font-weight: bold\">/</span> (m <span style=\"color: #AA22FF; font-weight: bold\">*</span> (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>)))), m, (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(lv1, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, m, (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))) <span style=\"color: #AA22FF; font-weight: bold\">/</span> (m <span style=\"color: #AA22FF; font-weight: bold\">*</span> (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>)))), m, (((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transpose_qkv(num_heads=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">transpose_output</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;bh&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;ndh&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        bh <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        ndh <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)), <span style=\"color: #008000\">2</span>, m, ndh), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>, m, ndh))\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)), m, <span style=\"color: #008000\">2</span>, ndh), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>transpose(lv, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>])\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)), m, (((((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(lv1, ((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)), m, <span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>))\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)), m, (((((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((((bh <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh) <span style=\"color: #AA22FF; font-weight: bold\">/</span> ((<span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> ndh)) <span style=\"color: #AA22FF; font-weight: bold\">*</span> m))), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transpose_output(num_heads=2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "masked_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_dyn():\n",
    "    bb = relax.BlockBuilder()\n",
    "    b = T.Var(\"b\", \"int64\")\n",
    "    m, n = T.Var(\"m\", \"int64\"), T.Var(\"n\", \"int64\")\n",
    "    k = T.Var(\"k\", \"int64\")\n",
    "\n",
    "    type_anno = rx.DynTensorType(3, \"float32\")\n",
    "    type_anno1 = rx.DynTensorType(2, \"float32\")\n",
    "    x = rx.Var(\"x\", [b, m, n], type_anno)\n",
    "    valid_lens = rx.Var(\"valid_lens\", [n], type_anno1)\n",
    "    fn_inputs = [x, valid_lens]\n",
    "    fn_output = None\n",
    "    with bb.function(\"masked_softmax\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.reshape(x, (-1, n)))\n",
    "            lv1 = bb.emit_te(topi.sequence_mask, lv0, valid_lens, -1e6, 1)\n",
    "            output = bb.emit(relax.nn.softmax(lv1, axis=-1))\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()\n",
    "\n",
    "def masked_softmax(x_shape: R.Shape, valid_shape: R.Shape):\n",
    "    bb = relax.BlockBuilder()\n",
    "\n",
    "    x = rx.Var(\"x\", x_shape, rx.DynTensorType(len(x_shape), \"float32\"))\n",
    "    valid_lens = rx.Var(\"valid_lens\", valid_shape, rx.DynTensorType(len(valid_shape), \"int64\"))\n",
    "\n",
    "    fn_inputs = [x, valid_lens]\n",
    "    fn_output = None\n",
    "    with bb.function(\"masked_softmax\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit(relax.op.reshape(x, (-1, x_shape[2])))\n",
    "            lv1 = bb.emit_te(topi.sequence_mask, lv0, valid_lens, -1e6, 1)\n",
    "            output = bb.emit(relax.nn.softmax(R.reshape(lv1, x_shape), axis=-1))\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()\n",
    "\n",
    "# def rx_masked_softmax(x: rx.Expr, valid_lens: rx.Expr)-> rx.Expr:\n",
    "#     print(x.shape)\n",
    "\n",
    "def rx_masked_softmax(x: rx.Expr, valid_lens: rx.Expr)-> rx.Expr:\n",
    "    # print(x.shape)\n",
    "    # x_reshape = R.reshape(x, (-1, x.shape[2]))\n",
    "    # te_x, te_valid = rx.te_tensor(x_reshape, \"te_x\"), rx.te_tensor(valid_lens, \"te_valid\")\n",
    "    # R.match_shape(te_x, x_reshape.shape)\n",
    "    # R.match_shape(te_valid, valid_lens.shape)\n",
    "    # seq_m = topi.sequence_mask(te_x, valid_length=te_valid, mask_value=-1e6, axis=1)\n",
    "    # return R.nn.softmax(seq_m, axis=-1)\n",
    "    return R.nn.softmax(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">sequence_mask</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>), <span style=\"color: #BA2121\">&quot;int64&quot;</span>], T_sequence_mask: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_sequence_mask&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder_1[ax0], rxplaceholder[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_sequence_mask[ax0, ax1])\n",
       "                T_sequence_mask[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(rxplaceholder_1[ax0] <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> ax1, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1000000</span>), rxplaceholder[ax0, ax1], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">masked_softmax</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), valid_lens: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">30</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int64&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">200</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">30</span>))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(sequence_mask, (lv, valid_lens), (<span style=\"color: #008000\">200</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(lv1, (<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>))\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>softmax(lv2, axis<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">1</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv3\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masked_softmax(x_shape=(10, 20, 30), valid_shape=(30, )).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relax.expr.VarBinding(0x646f0b0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rx.VarBinding(var=rx.Var(\"masked_softmax\"), value=masked_softmax()[\"masked_softmax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rx.Var(\"A\", shape_annotation=(10, 20, 30), type_annotation=relax.DynTensorType(3, \"float32\"))\n",
    "B = rx.Var(\"B\", shape_annotation=(10, 10), type_annotation=relax.DynTensorType(1, \"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 30) (10, 10)\n"
     ]
    }
   ],
   "source": [
    "rx_masked_softmax(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">sequence_mask</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_sequence_mask: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64, m: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_sequence_mask <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_sequence_mask, [b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_sequence_mask&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder_1[ax0], rxplaceholder[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_sequence_mask[ax0, ax1])\n",
       "                T_sequence_mask[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(rxplaceholder_1[ax0] <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, ax1), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1000000</span>), rxplaceholder[ax0, ax1], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">masked_softmax</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), valid_lens: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;n&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">2</span>):\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, n))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(sequence_mask, (lv, valid_lens), ((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), (b, m), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>softmax(lv1, axis<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">1</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masked_softmax().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relax.expr.Function(0x7bb53d0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_softmax()[\"masked_softmax\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = relax.BlockBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobalVar(sequence_mask)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.add_func(masked_softmax()[\"masked_softmax\"], func_name=\"masked_softmax\")\n",
    "bb.add_func(masked_softmax()[\"sequence_mask\"], func_name=\"sequence_mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">masked_softmax</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;b&quot;</span>, <span style=\"color: #BA2121\">&quot;m&quot;</span>, <span style=\"color: #BA2121\">&quot;n&quot;</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), valid_lens: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #BA2121\">&quot;n&quot;</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">2</span>):\n",
       "        b <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        m <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, n))\n",
       "            lv1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(sequence_mask, (lv, valid_lens), ((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), (b, m), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>softmax(lv1, axis<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">1</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(((((b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m) <span style=\"color: #AA22FF; font-weight: bold\">*</span> n) <span style=\"color: #AA22FF; font-weight: bold\">/</span> n), n), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv2\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">sequence_mask</span>(var_rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_T_sequence_mask: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, b: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64, m: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        n <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>var(<span style=\"color: #BA2121\">&quot;int64&quot;</span>)\n",
       "        rxplaceholder <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder, [b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        rxplaceholder_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_rxplaceholder_1, [n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        T_sequence_mask <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_T_sequence_mask, [b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(b <span style=\"color: #AA22FF; font-weight: bold\">*</span> m <span style=\"color: #AA22FF; font-weight: bold\">*</span> n <span style=\"color: #AA22FF; font-weight: bold\">/</span> n, n):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_sequence_mask&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder_1[ax0], rxplaceholder[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_sequence_mask[ax0, ax1])\n",
       "                T_sequence_mask[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(rxplaceholder_1[ax0] <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(<span style=\"color: #BA2121\">&quot;float32&quot;</span>, ax1), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1000000</span>), rxplaceholder[ax0, ax1], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bb.get().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">func</span>(A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">40</span>, <span style=\"color: #008000\">30</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], B: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_batch_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">40</span>, <span style=\"color: #008000\">20</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "    <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>, <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>, <span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>]})\n",
       "    <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">40</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_batch_matmul_NN&quot;</span>):\n",
       "            b, i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSR&quot;</span>, [i0, i1, i2, i3])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[b, i, k], B[b, k, j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_batch_matmul_NN[b, i, j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> A[b, i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> B[b, k, j]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = te.placeholder(name=\"A\", shape=(10, 40, 30), dtype=\"float32\")\n",
    "B = te.placeholder(name=\"B\", shape=(10, 30, 20), dtype=\"float32\")\n",
    "C = topi.nn.batch_matmul(A, B, transpose_b=False)\n",
    "te.create_prim_func([A, B, C]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def te_bmm(A: te.Tensor, B: te.Tensor) -> te.Tensor:\n",
    "    assert(len(A.shape) == 3)\n",
    "    assert(len(B.shape) == 3)\n",
    "    assert(A.shape[-1] == B.shape[-2])\n",
    "    return topi.nn.batch_matmul(A, B, transpose_b=False)\n",
    "\n",
    "def bmm_t(A_shape: R.Shape, B_shape: R.Shape):\n",
    "    bb = relax.BlockBuilder()\n",
    "    # x = rx.Var(\"x\", (10, 20, 30), R.Tensor)\n",
    "    # y = rx.Var(\"y\", (10, 20, 30), R.Tensor)\n",
    "    x = rx.Var(\"x\", A_shape, R.Tensor)\n",
    "    y = rx.Var(\"y\", B_shape, R.Tensor)\n",
    "    fn_inputs = [x, y]\n",
    "    fn_output = None\n",
    "    with bb.function(\"bmm_t\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit_te(te_bmm, x, y)\n",
    "            fn_output = bb.emit_output(lv0)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmm_t((10, 20, 30), (10, 30, 40)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点积注意力机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotproduct_attention_dynamic():\n",
    "    bb = relax.BlockBuilder()\n",
    "    b = T.Var(\"b\", \"int64\")\n",
    "    q, d = T.Var(\"q\", \"int64\"), T.Var(\"d\", \"int64\")\n",
    "    k = T.Var(\"k\", \"int64\")\n",
    "\n",
    "    type_anno = rx.DynTensorType(3, \"float32\")\n",
    "    type_anno2 = rx.DynTensorType(3, \"float32\")\n",
    "    typa_anno3 = rx.DynTensorType(1, \"int64\")\n",
    "\n",
    "    queries = rx.Var(\"queries\", [b, q, d], type_anno)\n",
    "    keys = rx.Var(\"keys\", [b, k, d], type_anno2)\n",
    "    values = rx.Var(\"values\", [b, k, d], type_anno2)\n",
    "    valid_lens = rx.Var(\"valid_lens\", [b], typa_anno3)\n",
    "    \n",
    "    fn_inputs = [queries, keys, values, valid_lens]\n",
    "    fn_output = None\n",
    "    with bb.function(\"dotproduct_attention\"):\n",
    "        with bb.dataflow():\n",
    "            k_transpose = bb.emit(relax.op.transpose(keys, (0,2,1)))\n",
    "            lv0 = bb.emit_te(topi.nn.batch_matmul, rx.te_tensor(queries), rx.te_tensor(k_transpose))\n",
    "            scores = R.divide(lv0, math.sqrt(d))\n",
    "            attention_weights = bb.emit(masked_softmax()(scores, valid_lens))\n",
    "            output = bb.emit_te(topi.nn.batch_matmul, relax.nn.dropout(attention_weights), values)\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()\n",
    "\n",
    "def dotproduct_attention(queries_shape: R.Shape, keys_shape: R.Shape, \n",
    "            values_shape: R.Shape, valid_lens_shape: R.Shape):\n",
    "    bb = relax.BlockBuilder()\n",
    "\n",
    "    # add functions\n",
    "    mask_softmax_mod = masked_softmax(x_shape=(10, 20, 40), valid_shape=valid_lens_shape)\n",
    "    seq_mask = bb.add_func(mask_softmax_mod[\"sequence_mask\"], \"sequence_mask\")\n",
    "    rx_masked_softmax = bb.add_func(mask_softmax_mod[\"masked_softmax\"], \"masked_softmax\")\n",
    "\n",
    "    # relax args type\n",
    "    queries = rx.Var(\"queries\", queries_shape, rx.DynTensorType(len(queries_shape), \"float32\"))\n",
    "    keys = rx.Var(\"keys\", keys_shape, rx.DynTensorType(len(keys_shape), \"float32\"))\n",
    "    values = rx.Var(\"values\", values_shape, rx.DynTensorType(len(values_shape), \"float32\"))\n",
    "    valid_lens = rx.Var(\"valid_lens\", valid_lens_shape, rx.DynTensorType(len(valid_lens_shape), \"int64\"))\n",
    "    \n",
    "    d = queries.shape[2]\n",
    "    # relax func infos \n",
    "    fn_inputs = [queries, keys, values, valid_lens]\n",
    "    fn_output = None\n",
    "\n",
    "    with bb.function(\"dotproduct_attention\"):\n",
    "        with bb.dataflow():\n",
    "            lv0 = bb.emit_te(topi.nn.batch_matmul, queries, keys)\n",
    "            scores = bb.emit(R.divide(lv0, rx.const(math.sqrt(int(d)))))\n",
    "            attention_weights = bb.emit(rx_masked_softmax(scores, valid_lens))\n",
    "            w_dp = bb.emit(R.TupleGetItem(R.nn.dropout(attention_weights), 1))\n",
    "            output = bb.emit_te(topi.nn.batch_matmul, w_dp, values, transpose_b=False)\n",
    "            fn_output = bb.emit_output(output)\n",
    "        bb.emit_func_output(fn_output, fn_inputs)\n",
    "    return bb.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20, 40) (40,)\n",
      "(10, 20, 40)\n",
      "(10, 20, 40) (10, 40, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #AA22FF\">@tvm</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>script<span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #1E90FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">sequence_mask</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>), <span style=\"color: #BA2121\">&quot;int64&quot;</span>], T_sequence_mask: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">200</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_sequence_mask&quot;</span>):\n",
       "                ax0, ax1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SS&quot;</span>, [i0, i1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder_1[ax0], rxplaceholder[ax0, ax1])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_sequence_mask[ax0, ax1])\n",
       "                T_sequence_mask[ax0, ax1] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(rxplaceholder_1[ax0] <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> ax1, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1000000</span>), rxplaceholder[ax0, ax1], dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">batch_matmul1</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">100</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_batch_matmul_NN: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">100</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">100</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_batch_matmul_NN&quot;</span>):\n",
       "                b, i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSR&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[b, i, k], rxplaceholder_1[b, k, j])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_batch_matmul_NN[b, i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_batch_matmul_NN[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[b, i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[b, k, j]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">batch_matmul</span>(rxplaceholder: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], rxplaceholder_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>], T_batch_matmul_NT: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer[(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>)), <span style=\"color: #BA2121\">&quot;float32&quot;</span>]):\n",
       "        <span style=\"color: #007979; font-style: italic\"># function attr dict</span>\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;layout_free_buffers&quot;</span>: [<span style=\"color: #008000\">1</span>], <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: <span style=\"color: #008000; font-weight: bold\">True</span>})\n",
       "        <span style=\"color: #007979; font-style: italic\"># body</span>\n",
       "        <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">10</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">20</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">40</span>), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int64(<span style=\"color: #008000\">30</span>)):\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;T_batch_matmul_NT&quot;</span>):\n",
       "                b, i, j, k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSSR&quot;</span>, [i0, i1, i2, i3])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(rxplaceholder[b, i, k], rxplaceholder_1[b, j, k])\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(T_batch_matmul_NT[b, i, j])\n",
       "                <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                    T_batch_matmul_NT[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "                T_batch_matmul_NT[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T_batch_matmul_NT[b, i, j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> rxplaceholder[b, i, k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> rxplaceholder_1[b, j, k]\n",
       "    \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">dotproduct_attention</span>(queries: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), keys: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">40</span>, <span style=\"color: #008000\">30</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), values: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">40</span>, <span style=\"color: #008000\">100</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), valid_lens: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">40</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int64&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(batch_matmul, (queries, keys), (<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>divide(lv, <span style=\"color: #008000\">5.47723</span>)\n",
       "            lv2: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> masked_softmax(lv1, valid_lens)\n",
       "            lv3: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tuple(R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dropout(lv2, rate<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0.5</span>)\n",
       "            lv4: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv3[<span style=\"color: #008000\">1</span>]\n",
       "            lv5 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(batch_matmul1, (lv4, values), (<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">100</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            gv: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">100</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv5\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv\n",
       "        \n",
       "    <span style=\"color: #AA22FF\">@R</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>function\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #1E90FF\">masked_softmax</span>(x: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>), valid_lens1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">40</span>,), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int64&quot;</span>)) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor(<span style=\"color: #008000; font-weight: bold\">None</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>, ndim<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">3</span>):\n",
       "        <span style=\"color: #007979; font-style: italic\"># block 0</span>\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>dataflow():\n",
       "            lv6: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">200</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(x, (<span style=\"color: #AA22FF; font-weight: bold\">-</span><span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">40</span>))\n",
       "            lv11 <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_tir(sequence_mask, (lv6, valid_lens1), (<span style=\"color: #008000\">200</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>)\n",
       "            lv21: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>reshape(lv11, (<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>))\n",
       "            lv31: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> R<span style=\"color: #AA22FF; font-weight: bold\">.</span>nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>softmax(lv21, axis<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">1</span>)\n",
       "            gv1: R<span style=\"color: #AA22FF; font-weight: bold\">.</span>Tensor((<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">20</span>, <span style=\"color: #008000\">40</span>), dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> lv31\n",
       "            R<span style=\"color: #AA22FF; font-weight: bold\">.</span>output(gv1)\n",
       "        <span style=\"color: #008000; font-weight: bold\">return</span> gv1\n",
       "        \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dotproduct_attention(queries_shape=(10, 20, 30), \n",
    "            keys_shape=(10, 40, 30),\n",
    "            values_shape=(10, 40, 100), \n",
    "            valid_lens_shape=(40, )).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb.call_te`：根据te函数生成一个调用节点\n",
    "- 该函数将来自relax表达式的参数转换为tensor\n",
    "- 回调函数应该返回一个te tensor或者te tensor的列表, 参考emit_te的例子\n",
    "\n",
    "返回：\n",
    "- ret: tvm.relax.Call, 返回新创建的Call node节点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bb.emit_te`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = rx.BlockBuilder()\n",
    "n, m = tir.Var(\"n\", \"int64\"), tir.Var(\"m\", \"int64\")\n",
    "type_anno = rx.DynTensorType(2, \"float32\")\n",
    "x = rx.Var(\"x\", [n, m], type_anno)\n",
    "y = rx.Var(\"y\", [n, m], type_anno)\n",
    "\n",
    "def te_func(args, args_dict, msg):\n",
    "    A = args[0]\n",
    "    B = args_dict[\"B\"]\n",
    "    return te.compute((128, 128), lambda i, j: A[i, j] + B[i, j])\n",
    "\n",
    "with bb.function([x, y], \"rx_func\"):\n",
    "    out = bb.emit_te(te_func, [x], {\"B\": y}, msg=\"hello\")\n",
    "    bb.emit_func_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "047bc0e0a0db8ffc412b6c90af731a29e4cde2c7e9fec4cd0e85726cd15c0726"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
